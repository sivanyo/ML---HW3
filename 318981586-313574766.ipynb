{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML - 3 (V1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2Yn7RLFi4Nh"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfAs6aPijL0q"
      },
      "source": [
        "# Section 1: Quick data exploration and preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgXs7Kf-jVFL"
      },
      "source": [
        "df_raw = pd.read_csv('https://raw.githubusercontent.com/sivanyo/ML-HW3/main/variant_labeled.csv')\n",
        "df_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZntwtbcjiMw"
      },
      "source": [
        "**Q1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3r3TYVdjkR5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df_raw, test_size=0.2, random_state=12)\n",
        "\n",
        "# we are going to modify slices of dataset so pandas see it as 'SettingWithCopyWarning'. those msg are not relevant and annoying so...\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmG_IgBfj62e"
      },
      "source": [
        "**Q2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czAnb3smj8Ns"
      },
      "source": [
        "# dont know what to do - sex is categorial \n",
        "tmp = train.Sex.apply(lambda x: 1 if x=='M' else 0)  # we know there are no NaN vals in this col\n",
        "sns.kdeplot(data=tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp-NtNtBkwJP"
      },
      "source": [
        "**Q3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0ZMm9u5kvjF"
      },
      "source": [
        "g = sns.FacetGrid(train, col=\"BloodType\", height=3.5, aspect=.65, col_wrap=4)\n",
        "g.map(sns.kdeplot, \"VariantScore\")\n",
        "g.set_titles(col_template=\"{col_name}\", size=18)\n",
        "g.set_xlabels(size=18)\n",
        "for ax in g.axes:\n",
        " ax.grid(alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWDzhghi3I4o"
      },
      "source": [
        "# Preprocessing (data preparation)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_7owdhLch0g"
      },
      "source": [
        "def category_to_numeric(df):\n",
        "  normal_dist = ['O+', 'O-', 'B+', 'B-']\n",
        "  df['BloodType'] = df.BloodType.astype(str)\n",
        "  df['BloodType'] = df['BloodType'].apply(lambda x : 0 if x in normal_dist else 1)\n",
        "  df['BloodType'] = df.BloodType.astype(float)\n",
        "  df['Sex'] = df['Sex'].apply(lambda x : 1 if x=='M' else 0)\n",
        "\n",
        "category_to_numeric(train)\n",
        "category_to_numeric(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4-xflj_jjeE"
      },
      "source": [
        "train.corr()\n",
        "corr = train.corr()\n",
        "kot = corr[corr>=.9]\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.heatmap(kot, cmap=\"Greens\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_GcZ4NGhTmB"
      },
      "source": [
        "def remove_corr_feat(df):\n",
        "  df.drop('NrCousins', axis=1, inplace=True)\n",
        "  df.drop('StepsPerYear', axis=1, inplace=True)\n",
        "  df.drop('HouseholdExpenseParkingTicketsPerYear', axis=1, inplace=True)\n",
        "  df.drop('HouseholdExpenseOnSocialGames', axis=1, inplace=True)\n",
        "  # df.drop('HouseholdExpenseOnPresents', axis=1, inplace=True)\n",
        "\n",
        "remove_corr_feat(train)\n",
        "remove_corr_feat(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH6dy4O15no4"
      },
      "source": [
        "# this df will use us for the data preparation of the final test\n",
        "ppt = pd.DataFrame(columns = ['mean', 'median', 'max', 'min', 'high outlier', 'low outlier'])\n",
        "for col in train.columns.to_list()[1:-1]:\n",
        "  ppt.loc[col] = [train[col].mean(),train[col].median(),0,0,0,0]\n",
        "# ppt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chVJgPE7_QwS"
      },
      "source": [
        "# outliers and fillna\n",
        "\n",
        "alpha_all = 3.5\n",
        "alpha_for_pcr = 5\n",
        "\n",
        "for col in train.columns.to_list()[1:-1]:\n",
        "  q1 = train[col].quantile(0.25)\n",
        "  q3 = train[col].quantile(0.75)\n",
        "  iqr = q3-q1 \n",
        "  current_alpha = alpha_all\n",
        "  if 'PCR_' in col:\n",
        "    current_alpha = alpha_for_pcr\n",
        "  fence_low  = q1-current_alpha*iqr\n",
        "  if 'PCR_' not in col and fence_low < 0:\n",
        "    fence_low = 0\n",
        "  fence_high = q3+current_alpha*iqr\n",
        "  ppt.at[col, 'low outlier'] = fence_low\n",
        "  ppt.at[col, 'high outlier'] = fence_high\n",
        "\n",
        "ppt.at['AgeGroup', 'low outlier'] = 0  # manually set this 3 cols\n",
        "ppt.at['AgeGroup', 'high outlier'] = 9\n",
        "ppt.at['HappinessScore', 'low outlier'] = 1\n",
        "ppt.at['HappinessScore', 'high outlier'] = 10\n",
        "ppt.at['DisciplineScore', 'low outlier'] = 1\n",
        "ppt.at['DisciplineScore', 'high outlier'] = 10\n",
        "\n",
        "\n",
        "def fill_outliers(df):\n",
        "  for col in train.columns.to_list()[1:-1]:\n",
        "    m = ppt.at[col, 'median']\n",
        "    fence_low = ppt.at[col, 'low outlier']\n",
        "    fence_high = ppt.at[col, 'high outlier']\n",
        "    df[col] = df[col].apply(lambda row: m if (pd.isnull(row) or row < fence_low or row > fence_high) else row)\n",
        "\n",
        "\n",
        "fill_outliers(train)\n",
        "fill_outliers(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1Ime8TxEvLV"
      },
      "source": [
        "#normalization\n",
        "for col in train.columns.to_list()[1:-1]:\n",
        "  ppt.at[col, 'max'] = train[col].max()\n",
        "  ppt.at[col, 'min'] = train[col].min()\n",
        "\n",
        "\n",
        "def normalize(df):\n",
        "  for col in train.columns[1:-1]:\n",
        "    min = ppt.at[col, 'min']\n",
        "    max = ppt.at[col, 'max']\n",
        "    df[col] =  df[col].apply(lambda row: (row-min)/(max-min))\n",
        "\n",
        "\n",
        "normalize(train)\n",
        "normalize(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_rcjH-5GJ06"
      },
      "source": [
        "def preprocessing_data(df):\n",
        "  category_to_numeric(df)\n",
        "  remove_corr_feat(df)\n",
        "  fill_outliers(df)\n",
        "  normalize(df)\n",
        "\n",
        "  \n",
        "ppt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HkOLeh_iaVK"
      },
      "source": [
        "print(train.columns)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g6DoxWKibZZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaXv3-8pmWS3"
      },
      "source": [
        "# Section 2: Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOYSihN7xczi"
      },
      "source": [
        "errors_data = pd.DataFrame(columns= ['section', 'Train MSE', 'Validation MSE'])\n",
        "errors_data.loc['Dummy'] = [2, 0, 0]\n",
        "errors_data.loc['Basic Linear'] = [3, 0, 0]\n",
        "errors_data.loc['Multilevel linear'] = [4, 0, 0]\n",
        "errors_data.loc['Multilevel poly'] = [5, 0, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI_iNg0E0cmk"
      },
      "source": [
        "attributes = train.columns.to_list()\n",
        "features = attributes[1:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkNkSKdkqA8y"
      },
      "source": [
        "**Q6**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRVIjkTnmf9o"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "\n",
        "def CV_evaluation(h, X_train, y_train, n_splits=5):\n",
        "  scores = cross_validate(h, X_train, y_train, cv=n_splits,\n",
        "  scoring=make_scorer(mean_squared_error),\n",
        "  return_train_score=True)\n",
        "  \n",
        "  train_mse = scores['train_score'].mean()\n",
        "  valid_mse = scores['test_score'].mean()\n",
        "  \n",
        "  return (train_mse, valid_mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDsfm1jUqCpb"
      },
      "source": [
        "**Q7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PfnI5l5qEiL"
      },
      "source": [
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "dummy_regressor = DummyRegressor(strategy=\"mean\")\n",
        "# dummy_regressor.fit(train)\n",
        "\n",
        "x,y = CV_evaluation(dummy_regressor, train[features], train['VariantScore'])\n",
        "errors_data.loc['Dummy']['Train MSE'] = x\n",
        "errors_data.loc['Dummy']['Validation MSE'] = y\n",
        "\n",
        "errors_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju2fZ-VOsfMP"
      },
      "source": [
        "# Section 3: Basic linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw5gHX7nsiX3"
      },
      "source": [
        "**Q8**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASG0e2TutM07"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from matplotlib.pyplot import semilogx\n",
        "\n",
        "def tuning(data, features_list, print_flag=True):\n",
        "  train_scores, validation_scores = [], []\n",
        "  alpha_values = np.logspace(0, 5, num=100)\n",
        "  best_score_on_train, best_score_on_validation, best_alpha = 1, 1, 0\n",
        "  for val in alpha_values:\n",
        "    ridge = Ridge(val)\n",
        "    error = CV_evaluation(ridge, data[features_list], data['VariantScore'])\n",
        "    train_scores.append(error[0])\n",
        "    validation_scores.append(error[1])\n",
        "    if error[1] < best_score_on_validation:\n",
        "      best_score_on_validation = error[1]\n",
        "      best_score_on_train = error[0]\n",
        "      best_alpha = val\n",
        "  \n",
        "  if print_flag:\n",
        "    plt.semilogx(alpha_values, train_scores, 'r', label='train')\n",
        "    plt.semilogx(alpha_values, validation_scores, 'b', label='validation')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.title(\"Ridge classifier error as a function of alpha values\")\n",
        "    plt.show()\n",
        "\n",
        "  return best_score_on_train, best_score_on_validation, best_alpha\n",
        "\n",
        "best_score_on_train, best_score_on_validation, best_alpha = tuning(train, features_list=features) # got (0,0) means there is no regularization at all\n",
        "\n",
        "#  make sure this is the right plot + scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG0ex3W8w2hD"
      },
      "source": [
        "**Q9**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjTqOT7Myswr"
      },
      "source": [
        "errors_data.loc['Basic Linear']['Train MSE'] = best_score_on_train\n",
        "errors_data.loc['Basic Linear']['Validation MSE'] = best_score_on_validation\n",
        "\n",
        "errors_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GspSFUNAy6AW"
      },
      "source": [
        "**Q10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUiJ9Whay5dR"
      },
      "source": [
        "print(best_alpha)\n",
        "ridge = Ridge(best_alpha)\n",
        "ridge.fit(train[features], train['VariantScore'])\n",
        "print('w = ',ridge.coef_)\n",
        "# pd.Series(ridge.coef_, index = features).nlargest(10).plot(kind='barh')\n",
        "\n",
        "tmp = pd.Series(ridge.coef_, index = features)\n",
        "tmp = tmp.apply(lambda x: x if x>0 else -x)\n",
        "tmp = tmp.sort_values(axis=0)\n",
        "tmp.nlargest(10).plot(kind='barh')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md1S1slFqT43"
      },
      "source": [
        "# Section 4: Hierarchical linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VnrD9G4qVcu"
      },
      "source": [
        "**Q11**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTa39zUdqXjD"
      },
      "source": [
        "sns.kdeplot(data = train, x='AgeGroup', y='VariantScore', hue='Sex', color='b')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUoJ32Tls_In"
      },
      "source": [
        "now we will split the trainig set to feamles and males"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI8a-IsStFz2"
      },
      "source": [
        "females = train[train['Sex'] == 0]\n",
        "males = train[train['Sex'] == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4H3B3ZOsuQA"
      },
      "source": [
        "**Q12**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGxqM1pCsxE6"
      },
      "source": [
        "SexDataFrame = pd.DataFrame(columns= ['Train MSE', 'Validation MSE', 'Best alpha'])\n",
        "SexDataFrame.loc['Females'] = [0,0,0]\n",
        "SexDataFrame.loc['Males'] = [0,0,0]\n",
        "\n",
        "SexDataFrame.loc['Females']['Train MSE'], SexDataFrame.loc['Females']['Validation MSE'], SexDataFrame.loc['Females']['Best alpha'] = tuning(females, features)\n",
        "\n",
        "SexDataFrame.loc['Males']['Train MSE'], SexDataFrame.loc['Males']['Validation MSE'], SexDataFrame.loc['Males']['Best alpha'] = tuning(males, features)\n",
        "\n",
        "SexDataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kai_QR_hjb5z"
      },
      "source": [
        "best_score_on_train_f, best_score_on_validation_f, best_alpha_f = tuning(train[train['Sex'] == 0], features)\n",
        "best_score_on_train_m, best_score_on_validation_m, best_alpha_m = tuning(train[train['Sex'] == 1], features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAjQr4EEj9JT"
      },
      "source": [
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "class MultiRegressor(BaseEstimator, RegressorMixin):\n",
        "  def __init__(self, h_male, h_female):\n",
        "    self.h_male = h_male\n",
        "    self.h_female = h_female\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    x_m = X[X['Sex'] == 1]\n",
        "    y_m = y[x_m.index]\n",
        "    x_m = x_m.drop(['Sex'], axis = 1)\n",
        "    self.h_male.fit(x_m, y_m)\n",
        "\n",
        "    x_f = X[X['Sex'] == 0]\n",
        "    y_f = y[x_f.index]\n",
        "    x_f = x_f.drop(['Sex'], axis = 1)\n",
        "    self.h_female.fit(x_f, y_f)\n",
        "    return self\n",
        "\n",
        "  def predict(self, X):\n",
        "    # X should be a pandas dataframe\n",
        "    all_predictions = []\n",
        "\n",
        "    for index, x in X.iterrows():\n",
        "      fixed_x = x.drop(['Sex'])\n",
        "      y_pred = self.h_female.predict([fixed_x]) if x['Sex'] == 0 else self.h_male.predict([fixed_x])\n",
        "      all_predictions.append(y_pred[0])\n",
        "\n",
        "    return all_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxNolB4IlS0X"
      },
      "source": [
        "multi = MultiRegressor(Ridge(best_alpha_m), Ridge(best_alpha_f))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZGW8vTpn-Pd"
      },
      "source": [
        "**Q13**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl8Vvx4ZlEpm"
      },
      "source": [
        "errors = CV_evaluation(multi, train[features], train['VariantScore'])\n",
        "\n",
        "errors_data.loc['Multilevel linear']['Train MSE'] = errors[0]\n",
        "errors_data.loc['Multilevel linear']['Validation MSE'] = errors[1]\n",
        "\n",
        "errors_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sjTdw2cocG5"
      },
      "source": [
        "**Q14**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDBGv5v0oMM1"
      },
      "source": [
        "multi.fit(train[features], train['VariantScore'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifa2GKhiqy3T"
      },
      "source": [
        "# Section 5: Polynomial fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP3OC3hnv5mk"
      },
      "source": [
        "creating the new data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htYqRbYXj7Qb"
      },
      "source": [
        "def df_to_quad_df(df):\n",
        "  tmp_df = np.power(df, 2)\n",
        "  tmp_df.rename(columns=lambda x: x+\"_quadratic\", inplace=True)\n",
        "  df_quad = pd.concat([df ,tmp_df], axis=1, ignore_index=True)\n",
        "  df_quad.columns = list(df.columns) + list(tmp_df.columns)\n",
        "  for col in ['Sex_quadratic', 'ID_quadratic', 'BloodType_quadratic', 'VariantScore_quadratic']:\n",
        "    if (col in df_quad.columns):\n",
        "      df_quad.drop(col, axis=1, inplace=True)\n",
        "  return df_quad\n",
        "\n",
        "train_quadratic = df_to_quad_df(train)\n",
        "test_quadratic = df_to_quad_df(test)\n",
        "\n",
        "quad_features = train_quadratic.columns.to_list()\n",
        "quad_features.remove('VariantScore')\n",
        "quad_features.remove('ID')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i33hzKWt4QHF"
      },
      "source": [
        "**Q17**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lphoyuj94Js4"
      },
      "source": [
        "# this is what they mean ?\n",
        "SexDataFrame2 = pd.DataFrame(columns= ['Train MSE', 'Validation MSE', 'Best alpha'])\n",
        "SexDataFrame2.loc['Females'] = [0,0,0]\n",
        "SexDataFrame2.loc['Males'] = [0,0,0]\n",
        "\n",
        "best_score_on_train_f, best_score_on_validation_f, best_alpha_f = tuning(train_quadratic[train_quadratic['Sex'] == 0], features_list=quad_features)\n",
        "best_score_on_train_m, best_score_on_validation_m, best_alpha_m = tuning(train_quadratic[train_quadratic['Sex'] == 1], features_list=quad_features)\n",
        "\n",
        "SexDataFrame2.loc['Females']['Train MSE'], SexDataFrame2.loc['Females']['Validation MSE'], SexDataFrame2.loc['Females']['Best alpha'] = best_score_on_train_f, best_score_on_validation_f, best_alpha_f\n",
        "SexDataFrame2.loc['Males']['Train MSE'], SexDataFrame2.loc['Males']['Validation MSE'], SexDataFrame2.loc['Males']['Best alpha'] = best_score_on_train_m, best_score_on_validation_m, best_alpha_m\n",
        "\n",
        "SexDataFrame2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgVgKUjJ4bzO"
      },
      "source": [
        "multi_polynomial = MultiRegressor(Ridge(best_alpha_m), Ridge(best_alpha_f))\n",
        "multi_polynomial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcf-ZI7Z_k3O"
      },
      "source": [
        "**Q18**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVDsOYSs3cDt"
      },
      "source": [
        "multiScoreDF = pd.DataFrame(columns= ['Multilevel Model','Section', 'Sex', 'Train MSE', 'Valid MSE'])\n",
        "multiScoreDF = multiScoreDF.set_index([\"Multilevel Model\", \"Section\", \"Sex\"])\n",
        "for gender in ['M', 'F']:\n",
        "  multiScoreDF.loc['Linear', 4, gender] = [0,0]\n",
        "  multiScoreDF.loc['Polynomial', 5, gender] = [0,0]\n",
        "# multiScoreDF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbbmN3bC5cDe"
      },
      "source": [
        "Ridge_males = Ridge(best_alpha_m)\n",
        "Ridge_females = Ridge(best_alpha_f)\n",
        "\n",
        "err_train_m ,err_val_m = CV_evaluation(Ridge_males, males[features], males['VariantScore'])\n",
        "err_train_f ,err_val_f = CV_evaluation(Ridge_females, females[features], females['VariantScore'])\n",
        "\n",
        "multiScoreDF.loc['Linear', 4, 'M'] = [err_train_m ,err_val_m]\n",
        "multiScoreDF.loc['Linear', 4, 'F'] = [err_train_f ,err_val_f]\n",
        "\n",
        "quad_m = train_quadratic[train_quadratic['Sex'] == 1]\n",
        "quad_f = train_quadratic[train_quadratic['Sex'] == 0]\n",
        "\n",
        "\n",
        "err_train_m_quad ,err_val_m_quad = CV_evaluation(Ridge_males, quad_m[quad_features], quad_m['VariantScore'])\n",
        "err_train_f_quad ,err_val_f_quad = CV_evaluation(Ridge_females, quad_f[quad_features], quad_f['VariantScore'])\n",
        "\n",
        "multiScoreDF.loc['Polynomial', 5, 'M'] = [err_train_m_quad ,err_val_m_quad]\n",
        "multiScoreDF.loc['Polynomial', 5, 'F'] = [err_train_f_quad ,err_val_f_quad]\n",
        "\n",
        "multiScoreDF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_HJwefSGAE4"
      },
      "source": [
        "**Q20**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrRe1Ox52KFR"
      },
      "source": [
        "errors = CV_evaluation(multi_polynomial, train_quadratic[quad_features], train_quadratic['VariantScore'])\n",
        "\n",
        "errors_data.loc['Multilevel poly']['Train MSE'] = errors[0]\n",
        "errors_data.loc['Multilevel poly']['Validation MSE'] = errors[1]\n",
        "\n",
        "errors_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHoIPNxDFywn"
      },
      "source": [
        "# Section 6: Testing our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiBoiElNVhsW"
      },
      "source": [
        "tmp_arr = [0,0,0,0]\n",
        "dummy_regressor.fit(train[features], train['VariantScore'])\n",
        "tmp_arr[0] = mean_squared_error(test['VariantScore'], dummy_regressor.predict(test[features]))\n",
        "\n",
        "ridge = Ridge(best_alpha)\n",
        "ridge.fit(train[features], train['VariantScore'])\n",
        "tmp_arr[1] = mean_squared_error(test['VariantScore'], ridge.predict(test[features]))\n",
        "\n",
        "multi.fit(train[features], train['VariantScore'])\n",
        "tmp_arr[2] = mean_squared_error(test['VariantScore'], multi.predict(test[features]))\n",
        "\n",
        "multi_polynomial.fit(train_quadratic[quad_features], train_quadratic['VariantScore'])\n",
        "tmp_arr[3] = mean_squared_error(test_quadratic['VariantScore'], multi_polynomial.predict(test_quadratic[quad_features]))\n",
        "\n",
        "errors_data2 = errors_data.copy()\n",
        "errors_data2['Test MSE'] = tmp_arr\n",
        "errors_data2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnaDqsQNWdsQ"
      },
      "source": [
        "# Section 7: Custom models challenge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1gmGOOLuAjt"
      },
      "source": [
        "def get_top_feat(df, classifier_ctr, alpha, features_list):\n",
        "  clf = classifier_ctr(alpha)\n",
        "  clf.fit(df[features_list], df['VariantScore'])\n",
        "  #print('w = ',clf.coef_)\n",
        "\n",
        "  top_feat = pd.Series(clf.coef_, index = features_list)\n",
        "  top_feat = top_feat.apply(lambda x: x if x>0 else -x)\n",
        "  top_feat = top_feat.sort_values(axis=0)\n",
        "\n",
        "  # pd.Series(top_feat, index = features).nlargest(30).plot(kind='barh')\n",
        "  return top_feat, list(top_feat.keys())\n",
        "\n",
        "\n",
        "def tuning4 (df, classifier_ctr, features_list):\n",
        "  best_score = 100\n",
        "  best_alpha = -1000\n",
        "  for a in range(0,10000,25):\n",
        "    clf = classifier_ctr(alpha=a/1000)\n",
        "    ret = CV_evaluation(clf, df[features_list], df['VariantScore'])\n",
        "    # print(\"a: \" + str(a) + \", score: \" + str(ret[1]))\n",
        "    if ret[1] < best_score:\n",
        "      best_score = ret[1]\n",
        "      best_alpha = a/1000\n",
        "  print(\"best_score is: \" + str(best_score))\n",
        "  print(\"best_alpha is: \" + str(best_alpha))\n",
        "  return (best_score, best_alpha)\n",
        "\n",
        "\n",
        "def tuning_num_of_feat (df, classifier_ctr, alpha, features_list):\n",
        "  best_score = 100\n",
        "  best_n = 0\n",
        "  for n in range(5,len(features_list), 2):\n",
        "    select_feat = features_list[-1*n:]\n",
        "    clf = classifier_ctr(alpha)\n",
        "    ret = CV_evaluation(clf, df[select_feat], df['VariantScore'])\n",
        "    if ret[1] < best_score:\n",
        "      best_score = ret[1]\n",
        "      best_n = n\n",
        "  print(\"best_score is: \" + str(best_score))\n",
        "  print(\"best_n is: \" + str(best_n))\n",
        "  return (best_score, best_n)\n",
        "\n",
        "quad_features_no_sex = quad_features.copy()\n",
        "quad_features_no_sex.remove('Sex')\n",
        "quad_features_no_sex_no_blood = quad_features_no_sex.copy()\n",
        "quad_features_no_sex_no_blood.remove('BloodType')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shlysb4OAjdi"
      },
      "source": [
        "def build_clf(df, classifier_ctr, features_list):\n",
        "  best_multiExtra=0\n",
        "  feats = features_list\n",
        "  best_n_feat = 666\n",
        "\n",
        "  for i in range(1,4):\n",
        "    tmp, best_multiExtra = tuning4(df, classifier_ctr, feats[-1*best_n_feat:])\n",
        "    tmp, feats = get_top_feat(df, classifier_ctr, best_multiExtra, feats)\n",
        "    tmp, best_n_feat = tuning_num_of_feat(df, classifier_ctr, best_multiExtra, feats)\n",
        "\n",
        "  clf = classifier_ctr(best_multiExtra)\n",
        "  clf.fit(df[feats[-1*best_n_feat:]], df['VariantScore'])\n",
        "  return clf, feats[-1*best_n_feat:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwCrux2ZACNC"
      },
      "source": [
        "df_m_b0 = quad_m[quad_m['BloodType'] == 0]\n",
        "df_m_b1 = quad_m[quad_m['BloodType'] == 1]\n",
        "df_f_b0 = quad_f[quad_f['BloodType'] == 0]\n",
        "df_f_b1 = quad_f[quad_f['BloodType'] == 1]\n",
        "\n",
        "clf_m_b0, clf_m_b0_feat = build_clf(df_m_b0, Ridge, quad_features_no_sex_no_blood)\n",
        "clf_m_b1, clf_m_b1_feat = build_clf(df_m_b1, Ridge, quad_features_no_sex_no_blood)\n",
        "clf_f_b0, clf_f_b0_feat = build_clf(df_f_b0, Ridge, quad_features_no_sex_no_blood)\n",
        "clf_f_b1, clf_f_b1_feat = build_clf(df_f_b1, Ridge, quad_features_no_sex_no_blood)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIPZnq4Q1h2b"
      },
      "source": [
        "def custom_pred(X):\n",
        "  all_pred = []\n",
        "  for index, x in X.iterrows():\n",
        "    y_pred = 666\n",
        "    if x['Sex'] == 1:\n",
        "      if x['BloodType'] == 0:\n",
        "        y_pred = clf_m_b0.predict([x[clf_m_b0_feat]])\n",
        "      else:\n",
        "        y_pred = clf_m_b1.predict([x[clf_m_b1_feat]])\n",
        "    else:\n",
        "      if x['BloodType'] == 0:\n",
        "        y_pred = clf_f_b0.predict([x[clf_f_b0_feat]])\n",
        "      else:\n",
        "        y_pred = clf_f_b1.predict([x[clf_f_b1_feat]])\n",
        "    all_pred.append(y_pred[0])\n",
        "  return all_pred\n",
        "\n",
        "final_res = mean_squared_error(test_quadratic['VariantScore'], custom_pred(test_quadratic))\n",
        "print(final_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKs12M3y_n8r"
      },
      "source": [
        "final_res = mean_squared_error(test_quadratic['VariantScore'], custom_pred(df_to_quad_df(test)))\n",
        "print(final_res)  # used as validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c34nSwM1Z1Sb"
      },
      "source": [
        "# Section 8: Submitted model predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ341P1TZ6sC"
      },
      "source": [
        "unlabeled_raw = pd.read_csv('https://raw.githubusercontent.com/sivanyo/ML-HW3/main/variant_unlabeled.csv')\n",
        "# unlabeled_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-rLWaBob6Xs"
      },
      "source": [
        "unlabeled = unlabeled_raw.copy()\n",
        "preprocessing_data(unlabeled)\n",
        "# unlabeled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVVF1ZwThbfV"
      },
      "source": [
        "all_df = df_raw.copy()\n",
        "preprocessing_data(all_df) \n",
        "all_df_quad = df_to_quad_df(all_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcdbMwdt2RdI"
      },
      "source": [
        "quad_all_m = all_df_quad[all_df_quad['Sex'] == 1]\n",
        "quad_all_f = all_df_quad[all_df_quad['Sex'] == 0]\n",
        "\n",
        "df_m_b0 = quad_all_m[quad_all_m['BloodType'] == 0]\n",
        "df_m_b1 = quad_all_m[quad_all_m['BloodType'] == 1]\n",
        "df_f_b0 = quad_all_f[quad_all_f['BloodType'] == 0]\n",
        "df_f_b1 = quad_all_f[quad_all_f['BloodType'] == 1]\n",
        "\n",
        "clf_m_b0, clf_m_b0_feat = build_clf(df_m_b0, Ridge, quad_features_no_sex_no_blood)\n",
        "clf_m_b1, clf_m_b1_feat = build_clf(df_m_b1, Ridge, quad_features_no_sex_no_blood)\n",
        "clf_f_b0, clf_f_b0_feat = build_clf(df_f_b0, Ridge, quad_features_no_sex_no_blood)\n",
        "clf_f_b1, clf_f_b1_feat = build_clf(df_f_b1, Ridge, quad_features_no_sex_no_blood)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLdXXP4MbFvS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "921e9ef8-47d2-4fd8-938a-93fa33d4847e"
      },
      "source": [
        "pred_unlabeled = pd.DataFrame(index=np.arange(unlabeled.shape[0]), columns = ['ID', 'VariantScore'])\n",
        "pred_unlabeled['ID'] = unlabeled['ID']\n",
        "unlabeled_quad = df_to_quad_df(unlabeled)\n",
        "\n",
        "\n",
        "ridge = Ridge(tuning(all_df, features, print_flag=False)[2])\n",
        "ridge.fit(all_df[features], all_df['VariantScore'])\n",
        "pred_unlabeled['VariantScore'] =  ridge.predict(unlabeled[features])\n",
        "pred_unlabeled.to_csv(\"pred_3.csv\", index=False)\n",
        "files.download(\"pred_3.csv\")\n",
        "\n",
        "\n",
        "multi = MultiRegressor(Ridge(best_alpha_m), Ridge(best_alpha_f))\n",
        "multi.fit(all_df[features], all_df['VariantScore'])\n",
        "pred_unlabeled['VariantScore'] =  multi.predict(unlabeled[features])\n",
        "pred_unlabeled.to_csv(\"pred_4.csv\", index=False)\n",
        "files.download(\"pred_4.csv\")\n",
        "\n",
        "\n",
        "multi_quad = MultiRegressor(Ridge(tuning(all_df_quad[all_df_quad['Sex'] == 1], features_list=quad_features, print_flag=False)[2]), Ridge(tuning(all_df_quad[all_df_quad['Sex'] == 0], print_flag=False, features_list=quad_features)[2]))\n",
        "multi_quad.fit(all_df_quad[quad_features], all_df_quad['VariantScore'])\n",
        "pred_unlabeled['VariantScore'] =  multi_quad.predict(unlabeled_quad[quad_features])\n",
        "pred_unlabeled.to_csv(\"pred_5.csv\", index=False)\n",
        "files.download(\"pred_5.csv\")\n",
        "\n",
        "\n",
        "pred_unlabeled['VariantScore'] = custom_pred(unlabeled_quad)\n",
        "pred_unlabeled.to_csv(\"pred_7.csv\", index=False)\n",
        "files.download(\"pred_7.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_949309bb-d2a5-4ef3-a72b-900920257223\", \"pred_3.csv\", 48582)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_20a646ce-719d-4c5b-bef0-5e30c993fbb0\", \"pred_4.csv\", 48737)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a50ccce3-a97f-4e7d-84f1-ba3b595c83b5\", \"pred_5.csv\", 48732)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_73abf3ca-a3f5-426d-9a4a-0e0c92af8ff2\", \"pred_7.csv\", 48771)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xgfjCrNq0qq"
      },
      "source": [
        "# טיוטה"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DysKL9XfIVtS",
        "outputId": "31603591-f228-48a6-fa22-eaa72a0a7664"
      },
      "source": [
        "# # this is to make sure we predicing unlabeled as we want to (check by trying the same proccess on test)\n",
        "# unlabeled = test.copy()\n",
        "# unlabeled.drop('VariantScore', axis=1, inplace=True)\n",
        "# pred_unlabeled = pd.DataFrame(index=np.arange(unlabeled.shape[0]), columns = ['ID', 'VariantScore'])\n",
        "# pred_unlabeled['ID'] = unlabeled['ID']\n",
        "# unlabeled_quad = df_to_quad_df(unlabeled)\n",
        "\n",
        "# ridge = Ridge(tuning(all_df, features, print_flag=False)[2])\n",
        "# ridge.fit(all_df[features], all_df['VariantScore'])\n",
        "# pred_unlabeled['VariantScore'] =  ridge.predict(unlabeled[features])\n",
        "# pred_unlabeled.to_csv(\"pred_3.csv\", index=False)\n",
        "# # files.download(\"pred_3.csv\")\n",
        "# print(\"score3: \", mean_squared_error(pred_unlabeled['VariantScore'], test['VariantScore']))\n",
        "\n",
        "# multi = MultiRegressor(Ridge(best_alpha_m), Ridge(best_alpha_f))\n",
        "# multi.fit(all_df[features], all_df['VariantScore'])\n",
        "# pred_unlabeled['VariantScore'] =  multi.predict(unlabeled[features])\n",
        "# pred_unlabeled.to_csv(\"pred_4.csv\", index=False)\n",
        "# # files.download(\"pred_4.csv\")\n",
        "# print(\"score4: \", mean_squared_error(pred_unlabeled['VariantScore'], test['VariantScore']))\n",
        "\n",
        "# multi_quad = MultiRegressor(Ridge(tuning(all_df_quad[all_df_quad['Sex'] == 1], features_list=quad_features, print_flag=False)[2]), Ridge(tuning(all_df_quad[all_df_quad['Sex'] == 0], print_flag=False, features_list=quad_features)[2]))\n",
        "# multi_quad.fit(all_df_quad[quad_features], all_df_quad['VariantScore'])\n",
        "# pred_unlabeled['VariantScore'] =  multi_quad.predict(unlabeled_quad[quad_features])\n",
        "# pred_unlabeled.to_csv(\"pred_5.csv\", index=False)\n",
        "# # files.download(\"pred_5.csv\")\n",
        "# print(\"score5: \", mean_squared_error(pred_unlabeled['VariantScore'], test_quadratic['VariantScore']))\n",
        "\n",
        "# pred_unlabeled['VariantScore'] = custom_pred(unlabeled_quad)\n",
        "# pred_unlabeled.to_csv(\"pred_7.csv\", index=False)\n",
        "# # files.download(\"pred_7.csv\")\n",
        "# print(\"score7: \", mean_squared_error(pred_unlabeled['VariantScore'], test_quadratic['VariantScore']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score3:  0.007203004031778517\n",
            "score4:  0.0030599945277189444\n",
            "score5:  0.002316613598073224\n",
            "score7:  0.002146812888792962\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}